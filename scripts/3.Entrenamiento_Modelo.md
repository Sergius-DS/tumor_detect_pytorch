# Bloque 3: Entrenamiento del Modelo en PyTorch con Transfer Learning y Fine-Tuning

Este bloque describe el proceso completo para entrenar un modelo de Deep Learning basado en ResNet50 utilizando Transfer Learning en PyTorch, incluyendo la fase inicial de entrenamiento de solo las capas superiores y el ajuste fino (fine-tuning) de toda la red. Se implementan técnicas similares a las callbacks de Keras, como early stopping, reducción de tasa de aprendizaje y guardado del mejor modelo.

## 3.1 Construcción del Modelo ResNet50 Personalizado
Carga del Modelo Preentrenado: Se carga ResNet50 con pesos pre-entrenados en ImageNet, modificando la capa final para adaptarla a la clasificación binaria. La capa final es una nn.Linear con una neurona y función de activación sigmoide, agregada como parte del modelo.
Congelación de Capas Iniciales: En la primera fase, se congelan las capas convolucionales (todas menos la capa final personalizada) para que solo se entrenen las nuevas capas superiores.
Reemplazo de la Capa Final: La capa fc (fully connected) original se reemplaza por una secuencia que incluye Dropout y una capa lineal con salida de una neurona y activación sigmoide. Esto permite la clasificación binaria.

```python
# Cargar ResNet50 preentrenado
model = models.resnet50(pretrained=True)

# Congelar todas las capas (fases iniciales)
def set_parameter_requires_grad(model, feature_extracting=True):
    for param in model.parameters():
        param.requires_grad = not feature_extracting

set_parameter_requires_grad(model, feature_extracting=True)

# Reemplazar la capa final
num_features = model.fc.in_features
model.fc = nn.Sequential(
    nn.Dropout(0.5),
    nn.Linear(num_features, 1),
    nn.Sigmoid()
)

model = model.to(device)
```

## 3.2 Compilación y Configuración del Entrenamiento

Función de Pérdida: nn.BCELoss() para clasificación binaria.
Optimizador: Adam con tasa de aprendizaje inicial de 1e-3.
Métricas: Se monitorea la precisión y el AUC en validación para evaluar el rendimiento.

```python
criterion = nn.BCELoss()
optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3)
```

## 3.3 Entrenamiento en Fases con Early Stopping y ReduceLROnPlateau

## Fase 1: Entrenamiento de las Capas Nuevas

Se entrena solo la capa final (las capas convolucionales permanecen congeladas).
Se realiza por un número definido de épocas (ej. 10).
Callbacks implementados:
EarlyStopping: Se detiene el entrenamiento si la métrica val_auc no mejora tras patience=5 épocas.
ReduceLROnPlateau: Reduce la tasa de aprendizaje si val_loss no mejora después de 3 épocas.
Guardar Mejor Modelo: Se guarda el estado del modelo con mejor val_auc.

```python
best_auc = 0
patience = 5
counter = 0
initial_epochs = 10

for epoch in range(initial_epochs):
    # Entrenamiento y evaluación por epoch
    # ...
    # Si `val_auc` mejora, guardar el modelo
    if val_auc > best_auc:
        best_auc = val_auc
        torch.save(model.state_dict(), 'best_model_phase1.pth')
        counter = 0
    else:
        counter += 1
        if counter >= patience:
            print("Early stopping en fase 1")
            break
```

## Fase 2: Fine-Tuning de Todo el Modelo

Se descongelan las capas convolucionales (por ejemplo, layer4) y la capa final.
Se recompila el optimizador con una tasa de aprendizaje menor (ej. 1e-5).
Continúa el entrenamiento por un número adicional de épocas, con métricas y callbacks similares.

```python
# Descongelar capas específicas
for param in model.layer4.parameters():
    param.requires_grad = True
for param in model.fc.parameters():
    param.requires_grad = True

# Reconfigurar el optimizador
optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5)

# Entrenamiento en fase de fine-tuning
for epoch in range(fine_tune_epochs):
    # Entrenamiento y evaluación
    # ...
    # Guardar mejor modelo
    if val_auc > best_auc:
        best_auc = val_auc
        torch.save(model.state_dict(), 'best_model_phase2.pth')
        counter = 0
    else:
        counter += 1
        if counter >= patience:
            print("Early stopping en fase 2")
            break
```

## 3.4 Evaluación y Visualización de Resultados
Predicciones en Datos de Prueba: Se evalúa el modelo en el conjunto de test, generando probabilidades, matriz de confusión, reporte de clasificación, y curva ROC.
Métricas: Se calcula y visualiza la matriz de confusión, la curva ROC y el reporte de clasificación.

```python
# Cargar mejor modelo
model.load_state_dict(torch.load('best_model_final.pth'))

# Evaluación en test
model.eval()
all_probs = []
all_labels = []

with torch.no_grad():
    for images, labels in test_loader:
        images, labels = images.to(device), labels.float().to(device)
        outputs = model(images).squeeze()
        probs = outputs.cpu().numpy()
        all_probs.extend(probs)
        all_labels.extend(labels.cpu().numpy())
```

- Cálculo de métricas y visualización
- matriz de confusión, reporte de clasificación, curva ROC
