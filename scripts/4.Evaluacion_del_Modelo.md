Evaluación y Visualización del Modelo en PyTorch
Evaluación y Visualización del Modelo en PyTorch
Una vez que el modelo ResNet50 ha sido entrenado en dos fases (entrenamiento del clasificador y fine-tuning), el siguiente paso es evaluar su rendimiento en un conjunto de datos que no ha visto durante el entrenamiento: el conjunto de prueba. Además, se visualizan diversas métricas y el historial de entrenamiento para comprender mejor el comportamiento y la eficacia del modelo.

## 4.1 Evaluación del Modelo en el Conjunto de Prueba
Para realizar una evaluación sistemática en PyTorch, se puede seguir el siguiente procedimiento:

```python
import torch
import numpy as np
from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc
import matplotlib.pyplot as plt
import seaborn as sns

# Establecer el modo evaluación
model.eval()

# Listas para almacenar probabilidades y etiquetas verdaderas
all_probs = []
all_labels = []

with torch.no_grad():
    for images, labels in test_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images).squeeze()
        probs = outputs.cpu().numpy()
        all_probs.extend(probs)
        all_labels.extend(labels.cpu().numpy())

# Convertir en arrays numpy
y_probs = np.array(all_probs)
y_true = np.array(all_labels).astype(int)

# Predicciones binarizadas con umbral 0.5
y_pred = (y_probs > 0.5).astype(int)

# --- Matriz de Confusión ---
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(6,6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)
plt.title('Matriz de Confusión - ResNet en PyTorch')
plt.ylabel('Etiqueta Verdadera')
plt.xlabel('Etiqueta Predicha')
plt.show()

# --- Reporte de Clasificación ---
print("Reporte de Clasificación:")
print(classification_report(y_true, y_pred, target_names=label_encoder.classes_))

# --- Curva ROC ---
fpr, tpr, _ = roc_curve(y_true, y_probs)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(8,6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'Curva ROC (área = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('FPR')
plt.ylabel('TPR')
plt.title('Curva ROC - ResNet en PyTorch')
plt.legend(loc='lower right')
plt.grid(True)
plt.show()
```

Este proceso te permite obtener métricas clave como la matriz de confusión, precisión, recall, F1-score y la curva ROC, que evalúan la capacidad del modelo para distinguir entre las clases en datos no vistos

## 4.2 Visualización del Historial de Entrenamiento
Para analizar cómo progresó el entrenamiento a lo largo de las épocas, se recomienda almacenar y visualizar métricas como precisión y pérdida en entrenamiento y validación. Aquí tienes un ejemplo de cómo hacerlo en PyTorch:

```python
import matplotlib.pyplot as plt

# Listas para almacenar métricas durante el entrenamiento
train_acc_history = []
val_acc_history = []
train_loss_history = []
val_loss_history = []

# Durante cada época, después del entrenamiento, agregar métricas
# Ejemplo:
# train_acc_history.append(epoch_accuracy)
# val_acc_history.append(val_epoch_accuracy)
# train_loss_history.append(epoch_loss)
# val_loss_history.append(val_epoch_loss)

def plot_training_history(train_acc, val_acc, train_loss, val_loss, initial_epochs):
    plt.figure(figsize=(12, 6))
    # Exactitud
    plt.subplot(1, 2, 1)
    plt.plot(train_acc, label='Exactitud de Entrenamiento')
    plt.plot(val_acc, label='Exactitud de Validación')
    plt.axvline(x=initial_epochs, color='red', linestyle='--', label='Inicio Fine-Tuning')
    plt.xlabel('Época')
    plt.ylabel('Exactitud')
    plt.legend()
    plt.grid()

    # Pérdida
    plt.subplot(1, 2, 2)
    plt.plot(train_loss, label='Pérdida de Entrenamiento')
    plt.plot(val_loss, label='Pérdida de Validación')
    plt.axvline(x=initial_epochs, color='red', linestyle='--', label='Inicio Fine-Tuning')
    plt.xlabel('Época')
    plt.ylabel('Pérdida')
    plt.legend()
    plt.grid()

    plt.tight_layout()
    plt.show()
```

- Después de completar el entrenamiento en ambas fases, llama a:
- plot_training_history(train_acc_history, val_acc_history, train_loss_history, val_loss_history, initial_epochs)

Este gráfico ayuda a detectar problemas como sobreajuste o subajuste, y a entender cuán bien el proceso de entrenamiento y fine-tuning ha progresado.
